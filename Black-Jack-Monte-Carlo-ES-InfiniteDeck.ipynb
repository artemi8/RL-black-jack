{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b19138-fce0-4c5c-8b0c-7b3a10dae2b6",
   "metadata": {},
   "source": [
    "# Black Jack stylised environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ebec2-908d-4990-92ee-a77e5200a84d",
   "metadata": {},
   "source": [
    "## Deck Setup \n",
    "1. Card Suits : Spades, Hearts, Diamonds and Clubs\n",
    "2. Face Cards : Kings, Queens and Jacks\n",
    "3. Ace = Aces\n",
    "4. Number cards : 2 to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58621088-83ca-40eb-a941-713c119e1ded",
   "metadata": {},
   "source": [
    "# Card value setup\n",
    "\n",
    "1. Face cards : 10\n",
    "2. Ace : 11 if bust 1\n",
    "3. Number : Numerical value equal to their number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2366465d-f8ec-4a54-96c0-38e774232020",
   "metadata": {},
   "source": [
    "# Reward Function\n",
    "\n",
    "![Cost function](images/cost_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da79b1-f02b-4d9c-91b9-2b713dfb30a4",
   "metadata": {},
   "source": [
    "## Doubts\n",
    "1. When calculating the score for the hand, when there is unusable ace, should be count that as 1 or 11?\n",
    "2. How do we score and end the game when there is only one last card left in the deck and still the agent wants to stick?\n",
    "4. How do I make reward after each state and action, question seems to give reward only after a hand is finished?\n",
    "    1. *The reward in this game is sparse, as we only know how to label the last state in a hand with a reward. Think back to how the rewards are assigned in the chess example in the lectures - we give a non-zero reward at the end for a win/lose outcome and 0 otherwise for all other transitions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c44972e-0f91-45de-ba88-29af7d29beb5",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Run variations iteration and find the nth iteration when the agent's q values shows minimal change to tell when the agent reached a optimal policy\n",
    "2. Find other plots like training error, rewards throughout the iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226da6e-5362-49ef-9923-a84c69c5cfe0",
   "metadata": {},
   "source": [
    "# <font color='orange'>Inferences</font>\n",
    "\n",
    "1. Tendency to stick increases at an early point of time (in terms of sum of the hand as state) with decrease in Gamma value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d7b532-28b0-4560-91ff-5d6246854346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from utils.blackjack_env_builder import BlackJackStylised\n",
    "from utils.scorer import Scorer, quadratic_scorer\n",
    "from utils.evaluator import evaluate_agent\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.general import plot_monte_carlo_q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59c8694-d051-40a7-b09c-dd000f65c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MonteCarloES:\n",
    "#     '''\n",
    "#     Monte Carlo Exploring starts algorithm\n",
    "#     '''\n",
    "    \n",
    "#     # TODO Print the number of states and actions along with the defined init_configurations\n",
    "#     def __init__(self, states, actions, init_config:dict, verbose=False): # reward_function\n",
    "        \n",
    "#         self.states = states\n",
    "#         self.actions = actions\n",
    "#         self.init_config = init_config\n",
    "#         # self.reward_function = reward_function\n",
    "#         self.initialize_Q_returns()\n",
    "        \n",
    "#     def epsilon_greedy_policy(self, state):\n",
    "        \n",
    "#         if random.random() < self.init_config['epsilon']:\n",
    "#             return random.choice(self.actions)\n",
    "#         else:\n",
    "#             return self._exploit(state)\n",
    "        \n",
    "#     def _exploit(self, state):\n",
    "#         greedy_action = max(list(self.Q[state].keys()),\n",
    "#                                 key=lambda x: self.Q[state][x]['value'])\n",
    "#         return greedy_action\n",
    "        \n",
    "    \n",
    "#     def initialize_Q_returns(self):\n",
    "#         self.Q = {}\n",
    "#         # self.returns = {}\n",
    "#         for state in self.states:\n",
    "#             action_dict = {}\n",
    "#             for action in self.actions:\n",
    "#                 # self.returns[(state, action)] = {'mean':0, 'count':0}\n",
    "#                 action_dict[action] = {'value':self.init_config['init_state_action_val'], \n",
    "#                                        'count':0}\n",
    "#             self.Q[state] = action_dict\n",
    "            \n",
    "            \n",
    "#     # TODO Check this function\n",
    "#     def _moving_average_returns(self, state, action, G):\n",
    "        \n",
    "#         curr_val = self.Q[state][action]['value']\n",
    "#         count = self.Q[state][action]['count']\n",
    "        \n",
    "#         mov_avg = curr_val + ((G - curr_val)/count)\n",
    "#         # mov_avg = (curr_val * count + G)/ count \n",
    "        \n",
    "#         return mov_avg\n",
    "            \n",
    "        \n",
    "#     def policy_evaluation(self, episode):\n",
    "        \n",
    "#         # Starting from reverse order for policy evaluation\n",
    "#         # for episode in episodes:\n",
    "#         state_repeat_check = []\n",
    "#         G = 0\n",
    "#         for state, action, reward in reversed(episode):\n",
    "\n",
    "#             # TODO Check if returns are right\n",
    "#             G = self.init_config['gamma']*G + reward\n",
    "\n",
    "#             if (state, action) not in state_repeat_check:\n",
    "#                 state_repeat_check.append((state, action))\n",
    "#                 self.Q[state][action]['count'] += 1\n",
    "#                 self.Q[state][action]['value'] = self._moving_average_returns(state, action, G)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0093321e-27c2-47c2-be4c-431789f4a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloES:\n",
    "    '''\n",
    "    Monte Carlo Exploring starts algorithm\n",
    "    '''\n",
    "    \n",
    "    # TODO Print the number of states and actions along with the defined init_configurations\n",
    "    def __init__(self, init_config:dict, actions, verbose=False, epsilon_decay=False,\n",
    "                 epsilon_decay_param={\"min_epsilon\":0.05, \"max_epsilon\":0, \"decay_factor\":0.0005}): \n",
    "        \n",
    "        self.actions = actions\n",
    "        self.init_config = init_config\n",
    "        self.epsilon_decay_param = epsilon_decay_param\n",
    "        self.oldQ = None\n",
    "        if epsilon_decay:\n",
    "            self.epsilon_decay_param['max_epsilon'] = self.init_config['epsilon']\n",
    "        self.initialize_Q()\n",
    "        \n",
    "    def epsilon_greedy_policy(self, state):\n",
    "        \n",
    "        hand_sum, usable_ace = state\n",
    "        # hand_sum, usable_ace, deck_feature = state\n",
    "        if random.random() < self.init_config['epsilon']:\n",
    "            return random.choice(self.actions)\n",
    "        else:\n",
    "            ## return np.argmax(self.Q[int(current_sum), usable_ace, deck_feature])\n",
    "            return np.argmax(self.Q[int(hand_sum), usable_ace, :, 0])\n",
    "        \n",
    "\n",
    "        \n",
    "    def initialize_Q(self):\n",
    "        '''\n",
    "        Zero initialized Q values\n",
    "        '''\n",
    "        self.Q = np.zeros((len(self.init_config['states']['state_dim_1']),\n",
    "                           len(self.init_config['states']['state_dim_2']), len(self.actions), 2)) \n",
    "        \n",
    "    \n",
    "    def epsilon_decay(self, episode_num):\n",
    "        \n",
    "        min_epsilon = self.epsilon_decay_param['min_epsilon']\n",
    "        max_epsilon = self.epsilon_decay_param['max_epsilon']\n",
    "        decay_factor = self.epsilon_decay_param['decay_factor']\n",
    "        \n",
    "        self.init_config['epsilon'] = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_factor*episode_num) \n",
    "            \n",
    "    def _moving_average_returns(self, hand_sum, usable_ace, action, G):\n",
    "        \n",
    "        curr_val = self.Q[hand_sum][usable_ace][action][0]\n",
    "        count = self.Q[hand_sum][usable_ace][action][1]\n",
    "        \n",
    "        mov_avg = curr_val + ((G - curr_val)/count)\n",
    "        # mov_avg = (curr_val * count + G)/ count + 1 \n",
    "        \n",
    "        return mov_avg\n",
    "            \n",
    "        \n",
    "    def policy_evaluation(self, episode):\n",
    "        \n",
    "        # Starting from reverse order for policy evaluation\n",
    "        # for episode in episodes:\n",
    "        state_repeat_check = []\n",
    "        G = 0\n",
    "        for hand_sum, usable_ace, action, reward in reversed(episode):\n",
    "\n",
    "            G = self.init_config['gamma']*G + reward\n",
    "\n",
    "            if (hand_sum, usable_ace, action) not in state_repeat_check:\n",
    "                state_repeat_check.append((int(hand_sum), usable_ace, action))\n",
    "                # print(self.Q.shape)\n",
    "                # print([int(hand_sum),usable_ace, action,1])\n",
    "                # print()\n",
    "                # self.oldQ = np.copy(self.Q)\n",
    "                self.Q[int(hand_sum)][usable_ace][action][1] += 1\n",
    "                self.Q[int(hand_sum)][usable_ace][action][0] = self._moving_average_returns(int(hand_sum), usable_ace, action, G)\n",
    "\n",
    "                \n",
    "def has_converged(previous_Q, current_Q, threshold=0.001):\n",
    "    \n",
    "    previous_Q_temp = previous_Q[:,:,:,0].ravel()\n",
    "    current_Q_temp = current_Q[:,:,:,0].ravel()\n",
    "    # print(f' is check : {previous_Q_temp is current_Q_temp}')\n",
    "    \n",
    "    delta = np.abs(current_Q_temp - previous_Q_temp)  #np.abs(\n",
    "    # print(current_Q - previous_Q)\n",
    "    return np.sum(delta) < threshold\n",
    "\n",
    "\n",
    "\n",
    "def plot_q_values_(agent, offset=1, monte_carlo=False):\n",
    "    \n",
    "    \n",
    "    if monte_carlo:\n",
    "        x1 = range(2, 22)\n",
    "        q_stick1 = [agent.Q[sum_val - offset, 0, 0, 0] for sum_val in x1]\n",
    "        q_hit1 = [agent.Q[sum_val - offset, 0, 1, 0] for sum_val in x1]\n",
    "        \n",
    "        x2 = range(2, 22)\n",
    "        q_stick2 = [agent.Q[sum_val - offset, 1, 0, 0] for sum_val in x2]\n",
    "        q_hit2 = [agent.Q[sum_val - offset, 1, 1, 0] for sum_val in x2]\n",
    "    else:\n",
    "        x1 = range(1, 22)\n",
    "        q_stick1 = [agent.Q[sum_val - offset, 0, 0] for sum_val in x1]\n",
    "        q_hit1 = [agent.Q[sum_val - offset, 0, 1] for sum_val in x1]\n",
    " \n",
    "    # Set 2\n",
    "        x2 = range(1, 22)\n",
    "        q_stick2 = [agent.Q[sum_val - offset, 1, 0] for sum_val in x2]\n",
    "        q_hit2 = [agent.Q[sum_val - offset, 1, 1] for sum_val in x2]\n",
    " \n",
    "    # Plot 1\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 5))  # 2 rows, 1 column\n",
    "    bar_width = 0.25\n",
    "    bar_stick1 = [i - bar_width / 2 for i in x1]\n",
    "    bar_hit1 = [i + bar_width / 2 for i in x1]\n",
    "    ax1.bar(bar_stick1, q_stick1, bar_width, label='Stick')\n",
    "    ax1.bar(bar_hit1, q_hit1, bar_width, label='Hit')\n",
    "    ax1.set_xlabel('Current Sum')\n",
    "    ax1.set_ylabel('Q-Value')\n",
    "    ax1.set_title('Without Usable Ace')\n",
    "    ax1.set_xticks(x1)\n",
    "    ax1.set_xticklabels(x1)\n",
    "    ax1.legend()\n",
    " \n",
    "    # Plot 2\n",
    "    bar_stick2 = [i - bar_width / 2 for i in x2]\n",
    "    bar_hit2 = [i + bar_width / 2 for i in x2]\n",
    "    ax2.bar(bar_stick2, q_stick2, bar_width, label='Stick')\n",
    "    ax2.bar(bar_hit2, q_hit2, bar_width, label='Hit')\n",
    "    ax2.set_xlabel('Current Sum')\n",
    "    ax2.set_ylabel('Q-Value')\n",
    "    ax2.set_title('With Usable Ace')\n",
    "    ax2.set_xticks(x2)\n",
    "    ax2.set_xticklabels(x2)\n",
    "    ax2.legend()\n",
    " \n",
    "    plt.tight_layout()  # Ensures subplots do not overlap\n",
    "    plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b7225-528f-4ff8-9b42-d2147f2ac5a5",
   "metadata": {},
   "source": [
    "## For infinite Decks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacbec9f-1296-431e-9497-164866027799",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BlackJackStylised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88a8b7dd-b726-4f78-96c5-59f4f57cc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_config= {'init_state_action_val': 0,\n",
    "              'epsilon' : 0.25,\n",
    "              'gamma' : 0.75,\n",
    "              'states' : {'state_dim_1':list(range(2, 23)),\n",
    "                          'state_dim_2': [0,1]}}\n",
    "agent_v1 = MonteCarloES(init_config=init_config, actions=[0, 1], epsilon_decay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c2e7ad6-9c7d-48b9-9292-25bfa4e048ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1000000/1000000 [01:30<00:00, 11042.05it/s]\n"
     ]
    }
   ],
   "source": [
    "cards, curr_sum, usable_ace, hand_complete = env.reset_init(hard=True)\n",
    "sum_offset = 1\n",
    "curr_sum -= sum_offset \n",
    "total_episodes = 1000000\n",
    "episode_break_flag = True\n",
    "# converged = False\n",
    "# counter = 0\n",
    "if not hand_complete:\n",
    "    # episodes = []\n",
    "    for i in tqdm(list(range(total_episodes))):\n",
    "    # agent_v1.oldQ = np.copy(agent_v1.Q)\n",
    "    # while not converged:\n",
    "        episode = []\n",
    "        episode_break_flag = True\n",
    "        while episode_break_flag:\n",
    "            action = agent_v1.epsilon_greedy_policy((curr_sum, int(usable_ace)))\n",
    "            cards, new_sum, new_usable_ace, hand_complete = env.step(action)\n",
    "            \n",
    "            \n",
    "            if new_sum > 21 or hand_complete == True:\n",
    "                episode_break_flag = False\n",
    "                reward = quadratic_scorer(new_sum) #new_sum\n",
    "                episode.append([curr_sum, int(usable_ace), action, reward])\n",
    "                curr_sum = new_sum - sum_offset\n",
    "                break\n",
    "            \n",
    "            reward = 0\n",
    "            episode.append([curr_sum, int(usable_ace), action, reward])\n",
    "            curr_sum = new_sum - sum_offset\n",
    "            usable_ace = new_usable_ace\n",
    "                \n",
    "        \n",
    "                \n",
    "        agent_v1.policy_evaluation(episode)\n",
    "        # if not counter % 40:\n",
    "        #     converged = has_converged(agent_v1.oldQ, agent_v1.Q, threshold=0.01)\n",
    "        #     agent_v1.oldQ = np.copy(agent_v1.Q)\n",
    "        # counter +=1\n",
    "        agent_v1.epsilon_decay(i)\n",
    "        # episodes.append(episode)\n",
    "        cards, curr_sum, usable_ace, hand_complete = env.reset_init()\n",
    "        curr_sum -= sum_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8869f21-87e2-4f22-9403-4822cdfb279c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_q_values_(agent_v1, offset=1, monte_carlo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768089ec-3294-4c67-a3ee-89ac3a52250e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec4355-c89e-4511-8e4a-83844377cd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf504032-d8b0-4e06-ac44-f52aeea3eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(n_eval_episodes, Q, num_decks=None):\n",
    "  # Assuming you have an instance of your environment\n",
    "    env = BlackJackStylised(num_decks=num_decks)\n",
    "    episode_rewards = []\n",
    "#   print(Q)\n",
    "    for episode in tqdm(range(n_eval_episodes)):\n",
    "        total_rewards_ep = 0\n",
    "        cards, current_sum, usable_ace, hand_complete = env.reset_init(hard=True)\n",
    "        # print(env.card_counter)\n",
    "        # deck_feature = get_deck_feature(env.card_counter)\n",
    "        # print(deck_feature)\n",
    "        state = (int(current_sum-2), int(usable_ace))\n",
    "        done = hand_complete\n",
    "        \n",
    "        if num_decks is not None:\n",
    "      \n",
    "            while not env.deck_complete: ## 1 episode\n",
    "                while not done: ## 1 Hand\n",
    "                    if  env.deck_complete:\n",
    "                        break\n",
    "                    # print(Q)\n",
    "                    # print(int(current_sum), usable_ace)\n",
    "                    # print(Q[int(current_sum), usable_ace])\n",
    "                    action = np.argmax(Q[int(current_sum-2), int(usable_ace)])\n",
    "                    # print(action)\n",
    "                    next_cards, next_sum, next_usable_ace, hand_complete = env.step(action)\n",
    "                    # print(next_cards)\n",
    "                    # next_deck_feature = get_deck_feature(env.card_counter)\n",
    "                    next_state = (next_sum-2, int(next_usable_ace))\n",
    "                    reward = 0 if not hand_complete else quadratic_scorer(next_sum)\n",
    "                    # if hand_complete:\n",
    "                    #   # print(next_cards, next_sum, next_usable_ace)\n",
    "                    #   # print('Reward: ', reward) \n",
    "                    # else:\n",
    "                    #   pass\n",
    "                    state = next_state\n",
    "                    current_sum = next_sum - 2\n",
    "                    usable_ace = next_usable_ace \n",
    "                    done = hand_complete\n",
    "\n",
    "                  # print('Hand Finished')\n",
    "                cards, current_sum, usable_ace, hand_complete = env.reset_init()\n",
    "            episode_rewards.append(reward)\n",
    "        else:\n",
    "            while not done: ## 1 Hand\n",
    "                # print(Q)\n",
    "                # print(int(current_sum), usable_ace)\n",
    "                # print(Q[int(current_sum), usable_ace])\n",
    "                action = np.argmax(Q[int(current_sum-2), int(usable_ace)])\n",
    "                # print(action)\n",
    "                next_cards, next_sum, next_usable_ace, hand_complete = env.step(action)\n",
    "                # print(next_cards)\n",
    "                # next_deck_feature = get_deck_feature(env.card_counter)\n",
    "                next_state = (next_sum-2, int(next_usable_ace))\n",
    "                reward = 0 if not hand_complete else quadratic_scorer(next_sum)\n",
    "                # if hand_complete:\n",
    "                #   # print(next_cards, next_sum, next_usable_ace)\n",
    "                #   # print('Reward: ', reward) \n",
    "                # else:\n",
    "                #   pass\n",
    "                state = next_state\n",
    "                current_sum = next_sum - 2\n",
    "                usable_ace = next_usable_ace \n",
    "                done = hand_complete\n",
    "\n",
    "                # print('Hand Finished')\n",
    "                cards, current_sum, usable_ace, hand_complete = env.reset_init()\n",
    "            episode_rewards.append(reward)\n",
    "       \n",
    "            \n",
    "    mean_reward = np.mean(episode_rewards)\n",
    "    std_reward = np.std(episode_rewards)\n",
    "\n",
    "    return mean_reward, std_reward\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74ae5d38-1c35-46a9-a1ac-24ebc13d571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 14632.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(61.6001, 39.241266289328635)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_agent(n_eval_episodes=10000, Q=agent_v1.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9011cd4-2b24-4aab-acbf-2b2879a7cbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
