{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b19138-fce0-4c5c-8b0c-7b3a10dae2b6",
   "metadata": {},
   "source": [
    "# Black Jack stylised environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ebec2-908d-4990-92ee-a77e5200a84d",
   "metadata": {},
   "source": [
    "## Deck Setup \n",
    "1. Card Suits : Spades, Hearts, Diamonds and Clubs\n",
    "2. Face Cards : Kings, Queens and Jacks\n",
    "3. Ace = Aces\n",
    "4. Number cards : 2 to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58621088-83ca-40eb-a941-713c119e1ded",
   "metadata": {},
   "source": [
    "# Card value setup\n",
    "\n",
    "1. Face cards : 10\n",
    "2. Ace : 11 if bust 1\n",
    "3. Number : Numerical value equal to their number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2366465d-f8ec-4a54-96c0-38e774232020",
   "metadata": {},
   "source": [
    "# Reward Function\n",
    "\n",
    "![Cost function](images/cost_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da79b1-f02b-4d9c-91b9-2b713dfb30a4",
   "metadata": {},
   "source": [
    "## Doubts\n",
    "1. When calculating the score for the hand, when there is unusable ace, should be count that as 1 or 11?\n",
    "2. How do we score and end the game when there is only one last card left in the deck and still the agent wants to stick?\n",
    "4. How do I make reward after each state and action, question seems to give reward only after a hand is finished?\n",
    "    1. *The reward in this game is sparse, as we only know how to label the last state in a hand with a reward. Think back to how the rewards are assigned in the chess example in the lectures - we give a non-zero reward at the end for a win/lose outcome and 0 otherwise for all other transitions.*\n",
    "5. MonteCarloES already achieves good result (That's what we think), verify it, if it is really the optimal result. And what would be be improving if we incorporated changing environment and using function approximation methods or policy gradient methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c44972e-0f91-45de-ba88-29af7d29beb5",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. Run variations iteration and find the nth iteration when the agent's q values shows minimal change to tell when the agent reached a optimal policy\n",
    "2. Find other plots like training error, rewards throughout the iterations\n",
    "3. Add Usable ace in the state\n",
    "4. <font color='red'> Consideration changing environment in the agent algorithm, if not suitable for MonteCarloES, try to implement another algorithm which might helps achieve that </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e226da6e-5362-49ef-9923-a84c69c5cfe0",
   "metadata": {},
   "source": [
    "# <font color='orange'>Inferences</font>\n",
    "\n",
    "1. Tendency to stick increases at an early point of time (in terms of sum of the hand as state) with decrease in Gamma value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d7b532-28b0-4560-91ff-5d6246854346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from utils.blackjack_env_builder import BlackJackStylised\n",
    "from utils.scorer import Scorer, quadratic_scorer\n",
    "from utils.evaluator import evaluate_agent\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.general import plot_monte_carlo_q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c59c8694-d051-40a7-b09c-dd000f65c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloES:\n",
    "    '''\n",
    "    Monte Carlo Exploring starts algorithm\n",
    "    '''\n",
    "    \n",
    "    # TODO Print the number of states and actions along with the defined init_configurations\n",
    "    def __init__(self, init_config:dict, actions, verbose=False, epsilon_decay=False,\n",
    "                 epsilon_decay_param={\"min_epsilon\":0.05, \"max_epsilon\":0, \"decay_factor\":0.0005}): \n",
    "        \n",
    "        self.actions = actions\n",
    "        self.init_config = init_config\n",
    "        self.epsilon_decay_param = epsilon_decay_param\n",
    "        if epsilon_decay:\n",
    "            self.epsilon_decay_param['max_epsilon'] = self.init_config['epsilon']\n",
    "        self.initialize_Q()\n",
    "        # self.oldQ = None\n",
    "        \n",
    "    def epsilon_greedy_policy(self, state):\n",
    "        \n",
    "        hand_sum, usable_ace = state\n",
    "        # hand_sum, usable_ace, deck_feature = state\n",
    "        if random.random() < self.init_config['epsilon']:\n",
    "            return random.choice(self.actions)\n",
    "        else:\n",
    "            ## return np.argmax(self.Q[int(current_sum), usable_ace, deck_feature])\n",
    "            return np.argmax(self.Q[int(hand_sum), usable_ace, :, 0])\n",
    "        \n",
    "\n",
    "        \n",
    "    def initialize_Q(self):\n",
    "        '''\n",
    "        Zero initialized Q values\n",
    "        '''\n",
    "        self.Q = np.zeros((len(self.init_config['states']['state_dim_1']),\n",
    "                           len(self.init_config['states']['state_dim_2']), len(self.actions), 2)) \n",
    "        \n",
    "    \n",
    "    def epsilon_decay(self, episode_num):\n",
    "        \n",
    "        if not self.epsilon_decay:\n",
    "            raise Exception('Epsion Decay is turned off!, Reinitialze the class with epsion decay flag to True')\n",
    "        min_epsilon = self.epsilon_decay_param['min_epsilon']\n",
    "        max_epsilon = self.epsilon_decay_param['max_epsilon']\n",
    "        decay_factor = self.epsilon_decay_param['decay_factor']\n",
    "        \n",
    "        self.init_config['epsilon'] = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_factor*episode_num) \n",
    "            \n",
    "    def _moving_average_returns(self, hand_sum, usable_ace, action, G):\n",
    "        \n",
    "        curr_val = self.Q[hand_sum][usable_ace][action][0]\n",
    "        count = self.Q[hand_sum][usable_ace][action][1]\n",
    "        \n",
    "        mov_avg = curr_val + ((G - curr_val)/count)\n",
    "        # mov_avg = (curr_val * count + G)/ count + 1 \n",
    "        \n",
    "        return mov_avg\n",
    "            \n",
    "        \n",
    "    def policy_evaluation(self, episode):\n",
    "        \n",
    "        # Starting from reverse order for policy evaluation\n",
    "        # for episode in episodes:\n",
    "        state_repeat_check = []\n",
    "        G = 0\n",
    "        for hand_sum, usable_ace, action, reward in reversed(episode):\n",
    "\n",
    "            G = self.init_config['gamma']*G + reward\n",
    "\n",
    "            if (hand_sum, usable_ace, action) not in state_repeat_check:\n",
    "                state_repeat_check.append((int(hand_sum), usable_ace, action))\n",
    "                \n",
    "                ## DEBUG\n",
    "                # if hand_sum < 10 and usable_ace:\n",
    "                #     print((hand_sum, usable_ace, action))\n",
    "                    \n",
    "                # print(self.Q.shape)\n",
    "                # print([int(hand_sum),usable_ace, action,1])\n",
    "                # print()\n",
    "                # self.oldQ = np.copy(self.Q)\n",
    "                self.Q[int(hand_sum)][usable_ace][action][1] += 1\n",
    "                self.Q[int(hand_sum)][usable_ace][action][0] = self._moving_average_returns(int(hand_sum), usable_ace, action, G)\n",
    "                \n",
    "                \n",
    "\n",
    "def has_converged(previous_Q, current_Q, threshold=0.001):\n",
    "    \n",
    "    previous_Q_temp = previous_Q[:,:,:,0].ravel()\n",
    "    current_Q_temp = current_Q[:,:,:,0].ravel()\n",
    "    # print(f' is check : {previous_Q_temp is current_Q_temp}')\n",
    "    \n",
    "    delta = np.abs(current_Q_temp - previous_Q_temp)  #np.abs(\n",
    "    # print(current_Q - previous_Q)\n",
    "    return np.sum(delta) < threshold\n",
    "\n",
    "\n",
    "def plot_q_values_(agent, offset=1, monte_carlo=False):\n",
    "    \n",
    "    \n",
    "    if monte_carlo:\n",
    "        x1 = range(2, 22)\n",
    "        q_stick1 = [agent.Q[sum_val - offset, 0, 0, 0] for sum_val in x1]\n",
    "        q_hit1 = [agent.Q[sum_val - offset, 0, 1, 0] for sum_val in x1]\n",
    "        \n",
    "        x2 = range(2, 22)\n",
    "        q_stick2 = [agent.Q[sum_val - offset, 1, 0, 0] for sum_val in x2]\n",
    "        q_hit2 = [agent.Q[sum_val - offset, 1, 1, 0] for sum_val in x2]\n",
    "    else:\n",
    "        x1 = range(1, 22)\n",
    "        q_stick1 = [agent.Q[sum_val - offset, 0, 0] for sum_val in x1]\n",
    "        q_hit1 = [agent.Q[sum_val - offset, 0, 1] for sum_val in x1]\n",
    " \n",
    "    # Set 2\n",
    "        x2 = range(1, 22)\n",
    "        q_stick2 = [agent.Q[sum_val - offset, 1, 0] for sum_val in x2]\n",
    "        q_hit2 = [agent.Q[sum_val - offset, 1, 1] for sum_val in x2]\n",
    " \n",
    "    # Plot 1\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 5))  # 2 rows, 1 column\n",
    "    bar_width = 0.25\n",
    "    bar_stick1 = [i - bar_width / 2 for i in x1]\n",
    "    bar_hit1 = [i + bar_width / 2 for i in x1]\n",
    "    ax1.bar(bar_stick1, q_stick1, bar_width, label='Stick')\n",
    "    ax1.bar(bar_hit1, q_hit1, bar_width, label='Hit')\n",
    "    ax1.set_xlabel('Current Sum')\n",
    "    ax1.set_ylabel('Q-Value')\n",
    "    ax1.set_title('Without Usable Ace')\n",
    "    ax1.set_xticks(x1)\n",
    "    ax1.set_xticklabels(x1)\n",
    "    ax1.legend()\n",
    " \n",
    "    # Plot 2\n",
    "    bar_stick2 = [i - bar_width / 2 for i in x2]\n",
    "    bar_hit2 = [i + bar_width / 2 for i in x2]\n",
    "    ax2.bar(bar_stick2, q_stick2, bar_width, label='Stick')\n",
    "    ax2.bar(bar_hit2, q_hit2, bar_width, label='Hit')\n",
    "    ax2.set_xlabel('Current Sum')\n",
    "    ax2.set_ylabel('Q-Value')\n",
    "    ax2.set_title('With Usable Ace')\n",
    "    ax2.set_xticks(x2)\n",
    "    ax2.set_xticklabels(x2)\n",
    "    ax2.legend()\n",
    " \n",
    "    plt.tight_layout()  # Ensures subplots do not overlap\n",
    "    plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b7225-528f-4ff8-9b42-d2147f2ac5a5",
   "metadata": {},
   "source": [
    "## For finite Decks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bacbec9f-1296-431e-9497-164866027799",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BlackJackStylised(num_decks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88a8b7dd-b726-4f78-96c5-59f4f57cc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_config= {'init_state_action_val': 0,\n",
    "              'epsilon' : 0.25,\n",
    "              'gamma' : 0.75,\n",
    "              'states' : {'state_dim_1':list(range(2, 23)),\n",
    "                          'state_dim_2': [0,1]}}\n",
    "agent_v1 = MonteCarloES(init_config=init_config, actions=[0, 1], epsilon_decay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c2e7ad6-9c7d-48b9-9292-25bfa4e048ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100000/100000 [05:04<00:00, 328.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# cards, curr_sum, usable_ace, hand_complete = env.reset_init(hard=True)\n",
    "total_episodes = 100000\n",
    "episode_break_flag = True\n",
    "\n",
    "# Offset to account for Q-value array indexing\n",
    "sum_offset = 2\n",
    "\n",
    "# DEBUG variables\n",
    "break_bool = False\n",
    "converge_flag = False\n",
    "# episodes = []\n",
    "for i in tqdm(list(range(total_episodes))):\n",
    "    episode = []\n",
    "    episode_break_flag = True\n",
    "    cards, curr_sum, usable_ace, hand_complete = env.reset_init(hard=True)\n",
    "    curr_sum -= sum_offset \n",
    "    \n",
    "    if not hand_complete:\n",
    "        while episode_break_flag:\n",
    "            action = agent_v1.epsilon_greedy_policy((curr_sum, int(usable_ace)))\n",
    "            # print(action)\n",
    "            cards, new_sum, new_usable_ace, hand_complete = env.step(action)\n",
    "\n",
    "\n",
    "            if new_sum > 21 or hand_complete == True:\n",
    "                \n",
    "                reward = quadratic_scorer(new_sum)\n",
    "                \n",
    "                episode.append([curr_sum, int(usable_ace), action, reward])\n",
    "                curr_sum = new_sum\n",
    "                \n",
    "                if env.deck_complete:\n",
    "                    episode_break_flag = False\n",
    "                    break\n",
    "                    \n",
    "                cards, curr_sum, usable_ace, hand_complete = env.reset_init()\n",
    "                curr_sum -= sum_offset\n",
    "                \n",
    "                if env.deck_complete:\n",
    "                    episode_break_flag = False\n",
    "                    break\n",
    "\n",
    "                continue\n",
    "\n",
    "            reward = 0\n",
    "            episode.append([curr_sum, int(usable_ace), action, reward])\n",
    "            curr_sum = new_sum - sum_offset\n",
    "            usable_ace = new_usable_ace\n",
    "\n",
    "\n",
    "    agent_v1.policy_evaluation(episode)\n",
    "\n",
    "   \n",
    "    agent_v1.epsilon_decay(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a35db057-191d-4107-9afb-499f2bd7b35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:08<00:00, 1111.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(62.0155, 39.195883199004456)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_agent(n_eval_episodes=10000, Q=agent_v1.Q, num_decks=4, offset=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49ede70f-4aaa-4443-80b1-490d241b45db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_q_values_(agent_v1, offset=2, monte_carlo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93fe3b9f-5b04-4e69-a053-5e5250c8853a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 2, 2, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_v1.Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "944c20df-dd0c-4079-a004-5520b4ab56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(n_eval_episodes, Q, num_decks=None, offset=1):\n",
    "  # Assuming you have an instance of your environment\n",
    "    env = BlackJackStylised(num_decks=num_decks)\n",
    "    episode_rewards = []\n",
    "#   print(Q)\n",
    "    for episode in tqdm(range(n_eval_episodes)):  \n",
    "        total_rewards_ep = 0\n",
    "        cards, current_sum, usable_ace, hand_complete = env.reset_init(hard=True)\n",
    "        # print(env.card_counter)\n",
    "        # deck_feature = get_deck_feature(env.card_counter)\n",
    "        # print(deck_feature)\n",
    "        state = (int(current_sum-offset), int(usable_ace))\n",
    "        done = hand_complete\n",
    "        \n",
    "        if num_decks is not None:\n",
    "            while not env.deck_complete: ## 1 episode\n",
    "                while not done: ## 1 Hand\n",
    "                    if  env.deck_complete:\n",
    "                        break\n",
    "                    # print(Q)\n",
    "                    # print(int(current_sum), usable_ace)\n",
    "                    # print(Q[int(current_sum), usable_ace])\n",
    "                    action = np.argmax(Q[int(current_sum-offset), int(usable_ace)])\n",
    "                    # print(action)\n",
    "                    next_cards, next_sum, next_usable_ace, hand_complete = env.step(action)\n",
    "                    # print(next_cards)\n",
    "                    # next_deck_feature = get_deck_feature(env.card_counter)\n",
    "                    next_state = (next_sum-offset, int(next_usable_ace))\n",
    "                    reward = 0 if not hand_complete else quadratic_scorer(next_sum)\n",
    "                    # if hand_complete:\n",
    "                    #   # print(next_cards, next_sum, next_usable_ace)\n",
    "                    #   # print('Reward: ', reward) \n",
    "                    # else:\n",
    "                    #   pass\n",
    "                    state = next_state\n",
    "                    current_sum = next_sum - offset\n",
    "                    usable_ace = next_usable_ace \n",
    "                    done = hand_complete\n",
    "\n",
    "                  # print('Hand Finished')\n",
    "                cards, current_sum, usable_ace, hand_complete = env.reset_init()\n",
    "            episode_rewards.append(reward)\n",
    "        else:\n",
    "            while not done: ## 1 Hand\n",
    "                # print(Q)\n",
    "                # print(int(current_sum), usable_ace)\n",
    "                # print(Q[int(current_sum), usable_ace])\n",
    "                action = np.argmax(Q[int(current_sum-offset), int(usable_ace)])\n",
    "                # print(action)\n",
    "                next_cards, next_sum, next_usable_ace, hand_complete = env.step(action)\n",
    "                # print(next_cards)\n",
    "                # next_deck_feature = get_deck_feature(env.card_counter)\n",
    "                next_state = (next_sum-offset, int(next_usable_ace))\n",
    "                reward = 0 if not hand_complete else quadratic_scorer(next_sum)\n",
    "                # if hand_complete:\n",
    "                #   # print(next_cards, next_sum, next_usable_ace)\n",
    "                #   # print('Reward: ', reward) \n",
    "                # else:\n",
    "                #   pass\n",
    "                state = next_state\n",
    "                current_sum = next_sum - offset\n",
    "                usable_ace = next_usable_ace \n",
    "                done = hand_complete\n",
    "\n",
    "                # print('Hand Finished')\n",
    "                cards, current_sum, usable_ace, hand_complete = env.reset_init()\n",
    "            episode_rewards.append(reward)\n",
    "       \n",
    "            \n",
    "    mean_reward = np.mean(episode_rewards)\n",
    "    std_reward = np.std(episode_rewards)\n",
    "\n",
    "    return mean_reward, std_reward\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8453fe21-b6ba-4976-846c-c9f3e00bdbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 935.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(62.344, 39.655941093359516)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_agent(n_eval_episodes=1000, Q=agent_v1.Q, num_decks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870dce1-bda3-4bba-a4c4-49c6182dcfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93beb637-d36d-4ad2-9b69-e79e1b90c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('company_data.pkl', 'wb') as outp:\n",
    "    company1 = Company('banana', 40)\n",
    "    pickle.dump(company1, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
